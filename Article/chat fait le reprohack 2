Excellente question ğŸ‘ â€” câ€™est un vrai problÃ¨me courant quand on travaille sur une **VM Ã©phÃ©mÃ¨re** (par ex. une instance cloud qui sâ€™efface Ã  chaque redÃ©marrage).

Tu veux donc une **solution persistante et automatisÃ©e** pour que ton environnement (Docker + Nextflow + images + progression du pipeline) soit restaurÃ© automatiquement Ã  chaque lancement.

Voici plusieurs **stratÃ©gies complÃ©mentaires**, classÃ©es du plus simple au plus robuste ğŸ‘‡

---

## ğŸª„ 1. Le â€œscript de bootstrapâ€ â€” un seul fichier Ã  exÃ©cuter

Tu peux crÃ©er un **script shell unique** (par ex. `setup.sh`) qui :

1. Installe Docker + Nextflow
2. TÃ©lÃ©charge (ou reconstruit) tes images Docker
3. Monte un rÃ©pertoire de donnÃ©es persistant (via volume ou disque)
4. Relance ton pipeline Nextflow Ã  partir de lâ€™Ã©tat prÃ©cÃ©dent

---

### ğŸ§± Exemple de `setup.sh`

```bash
#!/bin/bash
set -e

echo "=== Installation de Docker et Nextflow ==="
sudo apt update -y
sudo apt install -y docker.io curl openjdk-11-jre

if ! command -v nextflow &> /dev/null; then
  curl -s https://get.nextflow.io | bash
  sudo mv nextflow /usr/local/bin/
fi

echo "=== DÃ©marrage de Docker ==="
sudo systemctl start docker || true
sudo systemctl enable docker || true

echo "=== TÃ©lÃ©chargement des images nÃ©cessaires ==="
docker pull quay.io/biocontainers/sra-tools:3.0.5--hfca6b52_2
docker pull quay.io/biocontainers/trim-galore:0.6.7--hdfd78af_0
docker pull quay.io/biocontainers/bowtie2:2.5.1--py39hbc8fefb_0
docker pull quay.io/biocontainers/subread:2.0.6--hed695b0_0
docker pull bioconductor/deseq2:latest

echo "=== ExÃ©cution du pipeline Nextflow ==="
# le dossier 'work' et 'results' seront montÃ©s depuis un disque persistant
nextflow run main.nf --ACCESSION_ID SRR123456 --docker -resume
```

> ğŸ” Le `-resume` de Nextflow permet de **reprendre exactement lÃ  oÃ¹ le pipeline sâ€™est arrÃªtÃ©**, mÃªme aprÃ¨s redÃ©marrage.

---

## ğŸ“¦ 2. Utiliser un volume ou disque persistant

Tu veux que tes fichiers (inputs, outputs, cache Nextflow) **ne disparaissent pas** entre deux sessions.
Deux faÃ§ons de faire selon ton contexte :

### âœ… Option A â€” Volume Docker local

CrÃ©e un volume Docker pour stocker les donnÃ©es Nextflow :

```bash
docker volume create nfdata
```

Puis monte-le dans ton script ou ton pipeline :

```bash
nextflow run main.nf --docker -resume \
    -with-docker-volume nfdata:/mnt/data
```

### âœ… Option B â€” Disque persistant cloud

Si ta VM est sur GCP, AWS ou Azure :

* Monte un **disque persistant** dans `/mnt/nfdata` avant de lancer ton script.
* Dans ton script :

  ```bash
  export NXF_WORK=/mnt/nfdata/work
  export NXF_ASSETS=/mnt/nfdata/assets
  export NXF_HOME=/mnt/nfdata
  ```

Ainsi, Nextflow retrouvera automatiquement son cache et reprendra le pipeline.

---

## ğŸ§¬ 3. CrÃ©er une image Docker de ton environnement complet (VM containerisÃ©e)

Pour aller plus loin, tu peux tout empaqueter (Nextflow + images + ton pipeline) dans **une seule image Docker**, par exemple :

```dockerfile
FROM ubuntu:22.04
RUN apt update && apt install -y docker.io openjdk-11-jre curl
RUN curl -s https://get.nextflow.io | bash && mv nextflow /usr/local/bin/
COPY main.nf /pipeline/main.nf
WORKDIR /pipeline
ENTRYPOINT ["nextflow", "run", "main.nf", "--docker", "-resume"]
```

ğŸ‘‰ Ensuite tu nâ€™as quâ€™Ã  lancer ta VM et exÃ©cuter :

```bash
docker run -v /mnt/nfdata:/mnt/nfdata my_nextflow_pipeline
```

Tout sera automatique.

---

## ğŸ§  4. Utiliser un orchestrateur de workflow (optionnel)

Si tu fais souvent tourner ce pipeline sur des VMs temporaires, tu peux automatiser encore plus :

* **Terraform + cloud-init** â†’ crÃ©e la VM + exÃ©cute `setup.sh` au dÃ©marrage
* **GitHub Actions** ou **Nextflow Tower** â†’ gÃ¨rent les exÃ©cutions et la reprise automatique sur cloud

---

## ğŸ§© 5. Structure conseillÃ©e de ton rÃ©pertoire

```
project/
â”œâ”€â”€ setup.sh
â”œâ”€â”€ main.nf
â”œâ”€â”€ nextflow.config
â”œâ”€â”€ data/
â””â”€â”€ results/
```

Le dossier `data/` et `results/` doivent pointer vers un espace persistant montÃ© sur la VM (volume Docker, disque cloud, ou stockage rÃ©seau).

---

### âœ… En rÃ©sumÃ© : la solution la plus simple pour toi

1. CrÃ©e un script `setup.sh` (comme ci-dessus).
2. Monte un volume persistant `/mnt/nfdata`.
3. Utilise `nextflow run ... -resume` pour restaurer ton avancement.

Tu nâ€™auras plus quâ€™Ã  exÃ©cuter **une seule commande** :

```bash
bash setup.sh
```
